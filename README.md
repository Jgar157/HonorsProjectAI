# HonorsProjectAI
Honors Project for COP 3003

# Schedule (May be complete in less weeks)
Week  1 -> Aug 31 2020
Course Overview ✓
- Try solutions on your own first

Week  2 -> Sept 7
Introduction to AI ✓
- AI: Attempt to build machines capable of simulating intelligent human behavior
- ML: The science behind getting computers to act without being explicitly 
- Turing Test: Idea that computer and human should interact via command line with observer mointoring the dialogue. observer will be told that one of the participants ic omputers, and if the observer can't state which is human then the machine passes the test.
- It's important to know that intellgence and processing power are different.
- Data Exhaust is the trail of data that you leave behind throughout your day

Week  3 -> Sept 14
Data and Information ✓
- Data: Something to collect. Plural of datum.
- Info: The data in context, made meaningful.

Week  4 -> Sept 21
Categorizing Data ✓
- Supervised Learning: There is information but not enough information to learn.
  - Training algorithms need flexibility, otherwise it won't know how to handle new code.
- Unsupervised Learning: Structure of data is unknown and you're going in blind with the data.
  - Algorithms will draw inferences from datasets.
- Regression: when ranges of data are stored using real numbers Ex: Rainwater in mm

Week  5 -> Sept 28
Machine Learning: Why Now? ✓
- Data collection have become more accurate and frequent
- Computational power has increased and cloud capabilites has made processing power better
- There has been an explosion in jobs for data science and data analysis

Week  6 -> October 5
Machine Learning Workflow ✓
- There must be a problem to solve
- there must be data input, computational power, algorithms, and a starting point
- There must be a goal
- Crisp-DM model
  - Business Understanding
  - Data understanding
  - Data preparation
  - Modeling
  - valuation
  - Deployment

Week  7 -> October 12
Binary Trees ✓
- Consists of a root node with every node have 0,1, or 2 children.
- Nodes with no children are called a leaf
- 2 Nodes with the same parent are called siblings

Week  8 -> October 19
Recursion ✓
- Recursive methods can be intensive on RAM because it continuously adds onto the program stack
- There must be a base case where the recursion ends
- There must be a recursive case where the method calls back to itself

Week  9 -> October 26
Tree Traversal  ✓
- Preorder: Parent, Left child, right child
- In order: Left child, Parent, right child
- Postorder: Left child, right child, parent

Week 10 -> November 2
Yes/no Game  ✓
- Uses a decision tree to find the correct animal
- If the animal is not in the binary tree, then the user can add it
- All data is saved to a file

Week 11 -> November 9
Decision Tree Algorithm  ✓
- There are different types of decision tree algorithms
  - CART
  - Iterative Dichotomiser 3
  - C4.5
  - CHAID
  - Decision stump
  - Conditional Decision Trees

Week 12 -> November 16
Information Entropy  ✓
- Data with high level of uncertainty will contain more information
- If there is new data then there is more info
- Varaince is how far a set of data is spread

Week 13 -> November 23
ID3 Worked Example  ✓
- Entropy and Gain are essential for ID3
- First Entropy is found to find the label with the most entropy
- Then the Gain is used to find the label with the best spread

Week 14 -> November 30
Create an ID3 Tree  ✓
